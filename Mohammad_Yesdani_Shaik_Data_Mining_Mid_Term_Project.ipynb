{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187e857d-07eb-488b-a209-af7b9b8605ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\shaik\\anaconda3\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shaik\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing Package\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c91167-f017-415d-bb5e-4d762391aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Data Mining\n",
      "\n",
      "1: Amazon\n",
      "2: Best_Buy\n",
      "3: K-mart\n",
      "4: Nike\n",
      "5: Generic\n",
      "6: Custom\n",
      "7: Quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a Shopping Company from above:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 1: \"Amazon\" shop company\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Minimum support between (1% to 100%):  50\n",
      "Confidence between (1% to 100%):  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets from \"Brute Force\" Algorithm:\n",
      "                                           Itemsets  Frequency  Support\n",
      "0                               (Java For Dummies,)         13     65.0\n",
      "1        (Android Programming: The Big Nerd Ranch,)         13     65.0\n",
      "2                             (A Beginner’s Guide,)         11     55.0\n",
      "3                   (Java: The Complete Reference,)         10     50.0\n",
      "4  (Java For Dummies, Java: The Complete Reference)         10     50.0\n",
      "\n",
      "Manual Final Association Rules:\n",
      "Rule_1: ('Java For Dummies', 'Java: The Complete Reference') --> ('Java For Dummies',) Support: 50.0 Confidence: 76.92307692307693\n",
      "\n",
      "Rule_2: ('Java For Dummies', 'Java: The Complete Reference') --> ('Java: The Complete Reference',) Support: 50.0 Confidence: 100.0\n",
      "\n",
      "\n",
      "Frequent Itemsets from \"Apriori\" Algorithm:\n",
      "                                           Itemsets  Support\n",
      "0                              (A Beginner’s Guide)     55.0\n",
      "1         (Android Programming: The Big Nerd Ranch)     65.0\n",
      "2                                (Java For Dummies)     65.0\n",
      "3                    (Java: The Complete Reference)     50.0\n",
      "4  (Java: The Complete Reference, Java For Dummies)     50.0\n",
      "\n",
      "Final Association Rules from \"Apriori\" Algorithm:\n",
      "Rule_1: ('Java: The Complete Reference',), ('Java For Dummies',) --> ('Java For Dummies',) Support: 50.0 Confidence: 100.0\n",
      "\n",
      "Rule_2: ('Java For Dummies',), ('Java: The Complete Reference',) --> ('Java: The Complete Reference',) Support: 50.0 Confidence: 76.92307692307692\n",
      "\n",
      "\n",
      "Frequent Itemsets from \"FP-Tree Growth\" Algorithm:\n",
      "                                           Itemsets  Support\n",
      "0                                (Java For Dummies)     65.0\n",
      "1         (Android Programming: The Big Nerd Ranch)     65.0\n",
      "2                              (A Beginner’s Guide)     55.0\n",
      "3                    (Java: The Complete Reference)     50.0\n",
      "4  (Java: The Complete Reference, Java For Dummies)     50.0\n",
      "\n",
      "Final Association Rules from \"FP-Tree Growth\" Algorithm:\n",
      "Rule_1: ('Java: The Complete Reference',), ('Java For Dummies',) --> ('Java For Dummies',) Support: 50.0 Confidence: 100.0\n",
      "\n",
      "Rule_2: ('Java For Dummies',), ('Java: The Complete Reference',) --> ('Java: The Complete Reference',) Support: 50.0 Confidence: 76.92307692307692\n",
      "\n",
      "Time Taken by \"Brute Force\" Algorithm: 0.005233700037933886 seconds\n",
      "Time Taken by \"Apriori\" Algorithm: 0.007180799962952733 seconds\n",
      "Time Taken by \"FP-Tree Growth\" Algorithm: 0.005844699975568801 seconds\n",
      "\n",
      "Welcome to Data Mining\n",
      "\n",
      "1: Amazon\n",
      "2: Best_Buy\n",
      "3: K-mart\n",
      "4: Nike\n",
      "5: Generic\n",
      "6: Custom\n",
      "7: Quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a Shopping Company from above:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting.........\n"
     ]
    }
   ],
   "source": [
    "# Libraries Used\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
    "import timeit\n",
    "\n",
    "# Function for finding possible Itemsets\n",
    "def itemsetsFunc(items):\n",
    "    itemsets = [[]]\n",
    "    for item in items:\n",
    "        new_itemsets = []\n",
    "        for subset in itemsets:\n",
    "            new_subset = subset + [item]\n",
    "            new_itemsets.append(new_subset)\n",
    "        itemsets.extend(new_itemsets)\n",
    "    return itemsets[1:]\n",
    "\n",
    "# Brute Force Function with Association Rules\n",
    "def bruteFun(dataFrame, min_sup, confidence):\n",
    "        # Calculate frequency of individual items\n",
    "        trans = dataFrame[\"Transactions\"].str.split(\", \")\n",
    "        num_trans = len(trans)\n",
    "        subltt = []\n",
    "        for sublt in trans:\n",
    "            for item in sublt:\n",
    "                subltt.append(item)\n",
    "        item_frequency = pd.Series(subltt).value_counts()\n",
    "    \n",
    "        # Filtering the dataframe based on minimum support\n",
    "        freq_df = item_frequency[item_frequency >= (min_sup / 100) * num_trans].reset_index()\n",
    "        freq_df.columns = [\"Itemsets\", \"Frequency\"]\n",
    "        freq_df[\"Support\"] = (freq_df[\"Frequency\"] / num_trans) * 100\n",
    "    \n",
    "        # Generating itemsets\n",
    "        pos_itemsets = itemsetsFunc(freq_df[\"Itemsets\"])\n",
    "        itemsets = []\n",
    "        for item_set in pos_itemsets:\n",
    "            if len(item_set) > 1:\n",
    "                itemsets.append(item_set)\n",
    "\n",
    "        # Count of all itemsets\n",
    "        itemset_counts = {}\n",
    "        for it_set in itemsets:\n",
    "            count = 0\n",
    "            for transact in trans:\n",
    "                if set(it_set).issubset(set(transact)):\n",
    "                    count += 1\n",
    "            itemset_counts[tuple(it_set)] = count\n",
    "        itemset_support_df = pd.DataFrame(list(itemset_counts.items()), columns=[\"Itemsets\", \"Frequency\"])\n",
    "        itemset_support_df[\"Support\"] = (itemset_support_df[\"Frequency\"] / num_trans) * 100\n",
    "    \n",
    "        # Combining all frequent items and itemsets\n",
    "        all_freq_items = pd.concat([freq_df, itemset_support_df[itemset_support_df[\"Support\"] >= min_sup]], ignore_index=True)\n",
    "    \n",
    "        # Filtering the dataframe based on confidence\n",
    "        tuple_lt = []\n",
    "        for val in all_freq_items[\"Itemsets\"]:\n",
    "            if isinstance(val, str):\n",
    "                tu = tuple([val])\n",
    "                tuple_lt.append(tu)\n",
    "            else:\n",
    "                tuple_lt.append(val)\n",
    "        all_freq_items[\"Itemsets\"] = tuple_lt\n",
    "        item_support_dict = dict(zip(all_freq_items[\"Itemsets\"], all_freq_items[\"Support\"]))\n",
    "        final_dict = {}\n",
    "        final_sup_lt = []\n",
    "        for a in item_support_dict:\n",
    "            for b in item_support_dict:\n",
    "                if (set(b).issubset(a)) and (a != b):\n",
    "                    conf = (item_support_dict[a] / item_support_dict[b]) * 100\n",
    "                    final_dict[(a, b)] = conf\n",
    "                    final_sup_lt.append(item_support_dict[a])\n",
    "    \n",
    "        # Final Manual Association Rules\n",
    "        final_df = pd.DataFrame(final_dict.items(), columns=[\"Rules\", \"Confidence\"])\n",
    "        final_df[\"Support\"] = final_sup_lt\n",
    "        final_df = final_df[final_df[\"Confidence\"] >= confidence].reset_index(drop=True)\n",
    "        return final_df, all_freq_items\n",
    "\n",
    "# Using Apriori Algorithm Library\n",
    "def aprioriFun(dataFrame, min_sup, conf):\n",
    "    transAp = dataFrame[\"Transactions\"].str.get_dummies(sep=\", \")\n",
    "    transAp = transAp.astype(bool)\n",
    "    frequent_itemsets = apriori(transAp, min_support=min_sup, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=conf)\n",
    "    frequent_itemsets = frequent_itemsets.rename(columns={\"itemsets\": \"Itemsets\", \"support\": \"Support\"})\n",
    "    col_order = [\"Itemsets\", \"Support\"]\n",
    "    frequent_itemsets = frequent_itemsets[col_order]\n",
    "    frequent_itemsets[\"Support\"] = frequent_itemsets[\"Support\"] * 100\n",
    "    return rules, frequent_itemsets\n",
    "\n",
    "# Using FP-Tree Growth Algorithm Library\n",
    "def fptreeFun(dataFrame, min_sup, conf):\n",
    "    transFP = dataFrame[\"Transactions\"].str.get_dummies(sep=\", \")\n",
    "    transFP = transFP.astype(bool)\n",
    "    frequent_itemsets = fpgrowth(transFP, min_support=min_sup, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=conf)\n",
    "    frequent_itemsets = frequent_itemsets.rename(columns={\"itemsets\": \"Itemsets\", \"support\": \"Support\"})\n",
    "    col_order = [\"Itemsets\", \"Support\"]\n",
    "    frequent_itemsets = frequent_itemsets[col_order]\n",
    "    frequent_itemsets[\"Support\"] = frequent_itemsets[\"Support\"] * 100\n",
    "    return rules, frequent_itemsets\n",
    "\n",
    "# Printing Brute Force Final Association Rules\n",
    "def printingFinalData(final_df):\n",
    "    for i in range(len(final_df)):\n",
    "        for col in final_df.columns:\n",
    "            if col == \"Rules\":\n",
    "                print(f\"Rule_{i + 1}: {final_df.iloc[i][col][0]} --> {final_df.iloc[i][col][1]}\", end=\" \")\n",
    "                continue\n",
    "        print(f\"Support: {final_df.iloc[i][\"Support\"]} Confidence: {final_df.iloc[i][\"Confidence\"]}\\n\")\n",
    "\n",
    "# Printing Apriori and FP-Tree Growth Final Association Rules\n",
    "def printingFinalData_lib(final_df):\n",
    "    for j in range(len(final_df)):\n",
    "        print(f\"Rule_{j + 1}: {tuple(final_df.iloc[j][\"antecedents\"])}, {tuple(final_df.iloc[j][\"consequents\"])} --> {tuple(final_df.iloc[j][\"consequents\"])} Support: {final_df.iloc[j][\"support\"] * 100} Confidence: {final_df.iloc[j][\"confidence\"] * 100}\\n\")\n",
    "\n",
    "# Start of the program\n",
    "shop_company = {1: \"Amazon\", 2: \"Best_Buy\", 3: \"K-mart\", 4: \"Nike\", 5: \"Generic\", 6: \"Custom\", 7: \"Quit\"}\n",
    "\n",
    "# Creating While Loop for finding Frequent Itemsets and Association Rules for different transactions.\n",
    "while True:\n",
    "    print(\"\\nWelcome to Data Mining\\n\")\n",
    "    for num, name in shop_company.items():\n",
    "        print(f\"{num}: {name}\") \n",
    "    # Selecting Which Company Transactional Data to be Used.\n",
    "    sel_comp = int(input(\"\\nSelect a Shopping Company from above: \"))\n",
    "    if sel_comp == 7:\n",
    "        print(\"Quitting.........\")\n",
    "        break\n",
    "    print(f\"\\nYou have selected {sel_comp}: \\\"{shop_company[sel_comp]}\\\" shop company\\n\")\n",
    "    \n",
    "    # Giving Support and Confidence\n",
    "    min_support = float(input(\"Minimum support between (1% to 100%): \"))\n",
    "    confidence = float(input(\"Confidence between (1% to 100%): \"))\n",
    "\n",
    "    if sel_comp in shop_company:\n",
    "        # Load the selected company's dataset\n",
    "        data_link = f\"https://raw.githubusercontent.com/Yesdani20/Datasets/refs/heads/main/{shop_company[sel_comp]}_Dataset.csv\"\n",
    "        df = pd.read_csv(data_link)\n",
    "\n",
    "        # Executing Brute Force Algorithm\n",
    "        bruteForce_df, bruteForce_freqItems = bruteFun(df, min_support, confidence)\n",
    "        print(f\"\\nFrequent Itemsets from \\\"Brute Force\\\" Algorithm:\\n{bruteForce_freqItems}\")\n",
    "        print(f\"\\nManual Final Association Rules:\")\n",
    "        printingFinalData(bruteForce_df)\n",
    "\n",
    "        min_support_u = min_support / 100\n",
    "        confidence_u = confidence / 100\n",
    "\n",
    "        # Executing Apriori Algorithm\n",
    "        apriori_rules, apriori_freqItems = aprioriFun(df, min_support_u, confidence_u)\n",
    "        print(f\"\\nFrequent Itemsets from \\\"Apriori\\\" Algorithm:\\n{apriori_freqItems}\")\n",
    "        print(f\"\\nFinal Association Rules from \\\"Apriori\\\" Algorithm:\")\n",
    "        printingFinalData_lib(apriori_rules)\n",
    "\n",
    "        # Executing FP-Tree Growth Algorithm\n",
    "        fptree_rules, fptree_freqItems = fptreeFun(df, min_support_u, confidence_u)\n",
    "        print(f\"\\nFrequent Itemsets from \\\"FP-Tree Growth\\\" Algorithm:\\n{fptree_freqItems}\")\n",
    "        print(f\"\\nFinal Association Rules from \\\"FP-Tree Growth\\\" Algorithm:\")\n",
    "        printingFinalData_lib(fptree_rules)\n",
    "\n",
    "        # Calculating Time Taken for each Algorithm\n",
    "        print(f\"Time Taken by \\\"Brute Force\\\" Algorithm: {timeit.timeit(lambda: bruteFun(df, min_support, confidence), globals=globals(), number=1)} seconds\")\n",
    "        print(f\"Time Taken by \\\"Apriori\\\" Algorithm: {timeit.timeit(lambda: aprioriFun(df, min_support_u, confidence_u), globals=globals(), number=1)} seconds\")\n",
    "        print(f\"Time Taken by \\\"FP-Tree Growth\\\" Algorithm: {timeit.timeit(lambda: fptreeFun(df, min_support_u, confidence_u), globals=globals(), number=1)} seconds\")\n",
    "    else:\n",
    "        print(f\"{sel_comp} is an invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f1d59-9f64-4880-bf24-72a3bc7d7376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
